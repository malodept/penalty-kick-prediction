{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b320fe4e",
      "metadata": {
        "id": "b320fe4e"
      },
      "source": [
        "# 05 – Evaluation & Analysis\n",
        "\n",
        "In this notebook, we go beyond raw accuracy by analyzing the model's strengths and weaknesses:\n",
        "- confusion matrix\n",
        "- precision/recall/F1\n",
        "- examples of well-classified and misclassified penalties\n",
        "- class imbalance impact\n",
        "- per-player evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f1b1e3",
      "metadata": {
        "id": "95f1b1e3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# y_true, y_pred_classes viennent du notebook 04\n",
        "# Sinon : charger les arrays avec np.load() ou pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03b1805",
      "metadata": {
        "id": "f03b1805"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "target_names = ['g', 'm', 'd']\n",
        "print(classification_report(y_true, y_pred_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b255d5",
      "metadata": {
        "id": "81b255d5"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3642c42b",
      "metadata": {
        "id": "3642c42b"
      },
      "outputs": [],
      "source": [
        "# Analyse : erreurs les plus fréquentes\n",
        "errors = (y_true != y_pred_classes)\n",
        "print(f\"Nombre d'erreurs : {np.sum(errors)} / {len(y_true)}\")\n",
        "for i in np.where(errors)[0][:5]:\n",
        "    print(f\"→ Ex {i}: vrai={target_names[y_true[i]]}, prédit={target_names[y_pred_classes[i]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abeb5cda",
      "metadata": {
        "id": "abeb5cda"
      },
      "outputs": [],
      "source": [
        "# Répartition des prédictions\n",
        "from collections import Counter\n",
        "\n",
        "pred_counts = Counter(y_pred_classes)\n",
        "true_counts = Counter(y_true)\n",
        "\n",
        "plt.bar([target_names[i] for i in true_counts.keys()], true_counts.values(), alpha=0.6, label='true')\n",
        "plt.bar([target_names[i] for i in pred_counts.keys()], pred_counts.values(), alpha=0.6, label='pred')\n",
        "plt.title('Distribution: True vs Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cf855f",
      "metadata": {
        "id": "52cf855f"
      },
      "outputs": [],
      "source": [
        "# Sauvegarde des erreurs pour analyse future\n",
        "import pandas as pd\n",
        "\n",
        "df_errors = pd.DataFrame({\n",
        "    'true': [target_names[i] for i in y_true],\n",
        "    'pred': [target_names[i] for i in y_pred_classes],\n",
        "    'correct': y_true == y_pred_classes\n",
        "})\n",
        "\n",
        "df_errors.to_csv(\"errors_analysis.csv\", index=False)\n",
        "df_errors.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}