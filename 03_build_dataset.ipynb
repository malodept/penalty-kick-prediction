{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dfd738a",
      "metadata": {
        "id": "7dfd738a"
      },
      "source": [
        "# 03 – Build Dataset for LSTM Training\n",
        "\n",
        "In this notebook, we load the keypoints extracted by YOLOv7-Pose from each frame of each penalty video, aggregate them into temporal sequences, and assign them a class label (g/m/d).\n",
        "\n",
        " Input: keypoint `.txt` files from `yolov7/runs/pose/<video_name>/labels/`\n",
        "\n",
        " Labels: from `penalty_labels.csv`\n",
        "\n",
        " Output: NumPy arrays (X, y) ready for LSTM training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40025a4f",
      "metadata": {
        "id": "40025a4f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Chemins\n",
        "yolo_runs_dir = r\"D:/malo/Documents/yolov7/runs/pose\"\n",
        "labels_csv = r\"D:/malo/Documents/projets/penalty_prediction/penalty_dataset/penalty_labels.csv\"\n",
        "\n",
        "# Chargement des labels\n",
        "df_labels = pd.read_csv(labels_csv)\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2026a5",
      "metadata": {
        "id": "6c2026a5"
      },
      "outputs": [],
      "source": [
        "# Fonction pour charger les keypoints depuis un dossier /labels/\n",
        "def load_keypoints_from_folder(label_folder):\n",
        "    keypoints_seq = []\n",
        "    txt_files = sorted(Path(label_folder).glob(\"*.txt\"))\n",
        "\n",
        "    for txt_file in txt_files:\n",
        "        with open(txt_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            if not lines:\n",
        "                continue\n",
        "            coords = list(map(float, lines[0].strip().split()[1:]))  # sauter le class_id\n",
        "            keypoints_seq.append(coords)\n",
        "\n",
        "    return np.array(keypoints_seq)  # shape: (timesteps, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ec5385",
      "metadata": {
        "id": "f5ec5385"
      },
      "outputs": [],
      "source": [
        "# Construction du dataset complet\n",
        "X_list, y_list = [], []\n",
        "\n",
        "for _, row in df_labels.iterrows():\n",
        "    filename = row['filename'].replace(\".mp4\", \"\")\n",
        "    label = row['label']\n",
        "    label_folder = os.path.join(yolo_runs_dir, filename, \"labels\")\n",
        "\n",
        "    if not os.path.exists(label_folder):\n",
        "        print(f\"Dossier manquant pour {filename}, ignoré.\")\n",
        "        continue\n",
        "\n",
        "    seq = load_keypoints_from_folder(label_folder)\n",
        "    if len(seq) == 0:\n",
        "        continue\n",
        "    X_list.append(seq)\n",
        "    y_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342aab69",
      "metadata": {
        "id": "342aab69"
      },
      "outputs": [],
      "source": [
        "# Unifier les tailles avec padding (max length)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(X_list, padding='post', dtype='float32')\n",
        "label_map = {'g': 0, 'm': 1, 'd': 2}\n",
        "y = np.array([label_map[l] for l in y_list])\n",
        "\n",
        "print(\"Dataset prêt :\")\n",
        "print(\"X shape:\", X.shape)  # (n_samples, timesteps, features)\n",
        "print(\"y shape:\", y.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}