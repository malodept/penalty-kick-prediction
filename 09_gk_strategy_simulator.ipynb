{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "194b96ce",
      "metadata": {
        "id": "194b96ce"
      },
      "source": [
        "# 09 ‚Äì GK Strategy Simulator\n",
        "\n",
        "In this notebook, we simulate different goalkeeper strategies to anticipate penalty direction. We compare random guessing, naive historical strategies, and machine learning-based prediction.\n",
        "\n",
        "Goal: estimate how much a goalkeeper can improve performance by using statistical or ML insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d7f0ad",
      "metadata": {
        "id": "07d7f0ad"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "# Charger labels (ou y_true, y_pred_classes)\n",
        "labels_path = r\"D:/malo/Documents/projets/penalty_prediction/penalty_dataset/penalty_labels.csv\"\n",
        "df = pd.read_csv(labels_path)\n",
        "true_labels = df['label'].map({'g': 0, 'm': 1, 'd': 2}).values\n",
        "target_names = ['g', 'm', 'd']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "051729d1",
      "metadata": {
        "id": "051729d1"
      },
      "outputs": [],
      "source": [
        "# 1. Random Strategy\n",
        "random_preds = [random.randint(0, 2) for _ in true_labels]\n",
        "acc_random = accuracy_score(true_labels, random_preds)\n",
        "print(f\"Random GK Accuracy: {acc_random:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9258c6a0",
      "metadata": {
        "id": "9258c6a0"
      },
      "outputs": [],
      "source": [
        "# 2. Most Frequent Strategy (always guess most frequent direction)\n",
        "most_common = Counter(true_labels).most_common(1)[0][0]\n",
        "naive_preds = [most_common] * len(true_labels)\n",
        "acc_naive = accuracy_score(true_labels, naive_preds)\n",
        "print(f\"Naive GK Accuracy (always '{target_names[most_common]}'): {acc_naive:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4fb9cf",
      "metadata": {
        "id": "eb4fb9cf"
      },
      "outputs": [],
      "source": [
        "# 3. ML-Based Strategy (use existing model predictions if available)\n",
        "# y_pred_classes from your model should be available\n",
        "try:\n",
        "    acc_ml = accuracy_score(true_labels, y_pred_classes)\n",
        "    print(f\"ML-Based GK Accuracy: {acc_ml:.2%}\")\n",
        "except NameError:\n",
        "    print(\"‚ö†Ô∏è Please load `y_pred_classes` from model output (e.g. from notebook 04 or 05).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1550d8d4",
      "metadata": {
        "id": "1550d8d4"
      },
      "outputs": [],
      "source": [
        "# 4. Per-player strategy\n",
        "if 'player' in df.columns:\n",
        "    player_strategies = {}\n",
        "    for player in df['player'].unique():\n",
        "        subset = df[df['player'] == player]\n",
        "        common_dir = subset['label'].value_counts().idxmax()\n",
        "        correct = (subset['label'] == common_dir).mean()\n",
        "        player_strategies[player] = (common_dir, correct)\n",
        "\n",
        "    for p, (dir, acc) in player_strategies.items():\n",
        "        print(f\"üß† Player {p}: always diving {dir.upper()} = {acc:.2%} accuracy\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}